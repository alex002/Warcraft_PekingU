The s-IOT consists a linear CNT-based source array and a flat panel detector. A picture of the prototype is shown in Figure . The whole s-IOT system is mounted on a robotic arm, a flexible holder is made to hold the detector inside the patient's mouth. The x-ray coming from the linear source will be collimated to cover only the area of the detector. Once the imaging position is set up, the system stay stationary during the image acquisition. In this prototype system, 7 CNT-based x-ray sources are used with an angular coverage of about 10 degrees. This technology is patented by UNC and XinVivo LLC, and the patent is pending currently. Thus, the full system specifications of the s-IOT system and the prototype are not available for disclosure at this point. 

Due to the small FOV and a relatively large imaging angle, s-IOT images can have severe data truncation artifacts around the edges in the scanning direction. Truncation data correction method that is mentioned previously, therefore, has been implemented in the s-IOT reconstruction. One thing that should be noted here is that the x-ray source array is not guaranteed to be parallel to the detector. Therefore, the projection data "alignment" is needed before reconstruction using AFVR.

A(Two) dental teeth phantom was imaged using both the conventional bitewing setting and the s-IOT system. to .Figure  shows a 2D bitewing image. The reconstruction was run at 20 iterations with SIRT. 

Studies have shown that although DBT has better diagnostic accuracy on the masses, it does not visualize microcalcification as well as the 2D mammography. Thus, most of DBT systems in the market are FDA approval for use only in combined with the 2D mammography. This doubles the radiation dose to the patient, and increases the patient discomfort caused by the compression paddle. While the performance of the DBT imaging has improved significantly over the past few years and some researchers argues that DBT and DM(probably need to check this acronyme, and make sure it is mentioned previously) perform equally well in microcalcification with the current advances, many radiologists still prefer viewing 2D mammography in addition to the 3D tomosynthesis image. Part of that is because many radiologists were trained to read DM throughout their careers, the other reason, and probably the more important one, is that DM provides a faster workflow over the tomosynthesis images where one can get diagnostic information in one glance without the need to scroll through hundreds of images in DBT.  

One solution to reduce radiation dose and the screen time while still satisfy radiologist is the synthetic mammography. In this section, the method of generating synthetic mammography from the s-DBT will be investigated, in particular, the method to detect skin line and the algorithm to correct breast density. will be investigate. It should be note that the methods that discuss in this chapter is far from completed 

Discussion and Future direction: In theory, given the accurate reconstruction, the synthetic mammography could be as simple as one forward projection of the reconstruction. In practice, however, obtaining a good synthetic image is more complicated than a simple forward projection. First, the reconstruction images obtained in tomosynthesis imaging is far from accurate. The reconstruction does not converge due to the insufficient data, and image artifacts exist because of the data truncation, the image noise, the scatter, and the beam hardening effect. Secondly, in clinics, doctors are more concerned about how clear the useful diagnostic information is presented in the image rather than the quantitative accuracy of the image. As such, the synthetic image need to be “engineered” to aid diagnosis. At the same time, a balance is needed between the artificial enhancement and the image accuracy.

In this section, we discussed two methods that are necessary for synthetic mammography, namely detecting breast skin and breast density correction. 

Due to the complex nature of synthetic mammography, the two methods mentioned here are far from sufficient to obtain a good synthetic image. Future work is required to generate clinically useful synthetic mammography images. Given the nature of the tomosynthesis imaging, future research can be focused on two directions: the image artifact reduction and the image enhancement. It is known that DBT images contain many image artifacts, including the tomosynthesis artifact (out-of-plane artifact) and data truncation artifact. These image artifacts can severely degrade the image quality in the synthetic mammography, as the artifacts at various depths of the reconstruction will sum up in the final synthetic image. Fundamentally, if a better reconstruction is achieve. 

the  with  The synthetic mammography covers several parts of the image processing area, including . The techniques that discussed in the section is far from sufficient for a good synthetic mammography image. Additional research is required to improve the method further. First, tomosynthesis artifact reduction technique. Second, image enhancement technique. In artifact redu. Third, computed aid diagnosis. 



==============================================================


With the increased public awareness and concerns about x-ray radiation, the diagnostic imaging is heading to the direction of a safer diagnosis with reduced radiation dose. However, lower radiation dose reduces the x-ray photons that reaches the detector, thus lowering the signal strength and negatively affect the image quality, and consequently affect the diagnosis.  This raise a question to the research community: how to achieve better image quality at low dose. Many efforts has been made on the imaging hardware, including better detector, phase-contrast imaging, and innovative imaging geometry. As hardware is heavily constrainted by the physics, the improvement in imaging hardware is slow. Recent advances in software, mainly the image reconstruction and processing algorithms, have shine a light into this dilima. Statistically modeling incorporated with prior knowledge and efficient iterative algorithm has shown to be able to recover information that is not captured by the hardware, and the reconstruction from the statistical iterative reconstruction has demonstrated a superior image quality over the conventional FBP reconstruction. The only drawback is that such iterative reconstruction is time consuming, which is not practical in clinical setting. For digital tomosynthesis where the measured data are insufficient and truncated, the iterative reconstruction can greatly improve the final image quality which in terms benefits the diagnostic accuracy. 

The adapted fan volume reconstruction that we developed for the stationary tomosynthesis systems can dramatically improves the reconstruction speed. In our result, we observed 30 to 50 times’ speed up compared to the conventional 3D cone beam reconstruction on a six-cores desktop. Several aspects contribute to this improvement. First, each fan volume can be treated as independent to the adjacent fan volume. Therefore, each fan voluem reconstruction can be carried out separately, enabling a straightforward parallelization. Utilizing this advantage, we speed up the reconstruction by 6 times through parallel computing on MATLAB. Secondly, as the size of each reconstruction in AFVR is smaller than that in conventional cone-beam reconstruction, the size of the system matrix is dramatically reduced. Therefore, we are able to store the system matrix in the memory. This avoids the computation of the forward projector in each iteration, and reduces the reconstruction time. In addition, the system matrix of each fan volume are related by the tilted angle of the fan volume. As a result, the computation of system matrix can be much more efficient. Thirdly, AFVR improves the data locality, which allows a performance improvement through the caching mechanism.  

AFVR is designed for linear tomosynthesis, and it will not reconstruct images for conventional tomosynthesis systems with a curved line source motion, as generally the source positions in those systems will be different in height. This picture becomes clearer when one thinks of two source positions and connect them with one randomly-choosed detector row. The connections create two planes in the 3D space, each consists the same detector row but different sources. Since these source positions have different height, the two planes will cut the image space differently, or in another word, one voxel cut or included by the one plane might not be cut (included) in another plane. As a result, the value of those voxels can no longer be entirely determined by the projection data of a single detector row. With that being said, there is data redundancy even in the conventional tomosynthesis imaging (The value of one voxel is fully determined by only a fraction of the measurement), and one might be able to use that characteristic to designed an algorithm to speed up the reconstruction.

In this study, we used a FBP-based commercial software, RTT, to compare with the AFVR. While RTT can be used for a general tomosynthesis reconstruction, it is designed and optimized for the breast imaging. Therefore, it might not be fair to compare image quality between RTT and the proposed AFVR algorithm when reconstructing for a different imaging system. In addition, as a commercial software, RTT may consist proprietary imaging processing besides the reconstruction, which may affect the final reconstruction image. Therefore, our result may not apply to a general setting, i.e. the difference in image quality between AFVR and FBP reconstruction. Currently, the AFVR is coupled with SIRT, which is relatively simple and the reconstruction image quality is generally believed to be mediocre. We expect that the image quality can be further improved by incorporating a more sophisticate statistical model with AFVR. 
